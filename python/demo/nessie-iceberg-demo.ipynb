{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessie Demo\n",
    "===========\n",
    "This demo showcases how to use Nessie python API along with Spark3 from Iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Pyspark + Nessie environment\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from py4j.java_gateway import java_import\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.jars\", \"../../clients/iceberg/spark3/target/nessie-iceberg-spark3-0.1-SNAPSHOT.jar\") \\\n",
    "                    .config(\"spark.sql.execution.pyarrow.enabled\", \"true\") \\\n",
    "                    .config(\"spark.hadoop.fs.defaultFS\", 'file://' + os.getcwd() + '/spark_warehouse') \\\n",
    "                    .config(\"spark.hadoop.nessie.url\", \"http://localhost:19120/api/v1\") \\\n",
    "                    .config(\"spark.hadoop.nessie.ref\", \"main\") \\\n",
    "                    .config(\"spark.sql.catalog.nessie\", \"com.dremio.nessie.iceberg.spark.NessieIcebergSparkCatalog\") \\\n",
    "                    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "jvm = sc._gateway.jvm\n",
    "\n",
    "java_import(jvm, \"com.dremio.nessie.iceberg.NessieCatalog\")\n",
    "java_import(jvm, \"org.apache.iceberg.catalog.TableIdentifier\")\n",
    "java_import(jvm, \"org.apache.iceberg.Schema\")\n",
    "java_import(jvm, \"org.apache.iceberg.types.Types\")\n",
    "java_import(jvm, \"org.apache.iceberg.PartitionSpec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up nessie branches\n",
    "----------------------------\n",
    "\n",
    "- Branch `main` already exists\n",
    "- Create branch `dev`\n",
    "- List all branches (pipe JSON result into jq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/bin/nessie\", line 10, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/core.py\", line 1259, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context().obj, *args, **kwargs)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/pynessie/cli.py\", line 79, in create_branch\n",
      "    args[\"nessie\"].create_branch(branch, ref)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/pynessie/nessie_client.py\", line 54, in create_branch\n",
      "    create_branch(self._base_url, branch, ref, self._ssl_verify)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/pynessie/_endpoints.py\", line 145, in create_branch\n",
      "    _post(base_url + url, None, ssl_verify=ssl_verify)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/pynessie/_endpoints.py\", line 36, in _post\n",
      "    return _check_error(r, details)\n",
      "  File \"/home/ryan/workspace/nessie/python/demo/venv/lib/python3.7/site-packages/pynessie/_endpoints.py\", line 74, in _check_error\n",
      "    raise NessieConflictException(\"Entity already exists at \" + details, error, r)\n",
      "pynessie.error.NessieConflictException: Entity already exists at : 409 Client Error: Conflict for url: http://localhost:19120/api/v1/trees/branch/dev\n"
     ]
    }
   ],
   "source": [
    "!nessie create-branch dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"main\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"e0b41c30f0710277532f51242994e10acfdc46bf\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dev\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"e0b41c30f0710277532f51242994e10acfdc46bf\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nessie list-references | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables under dev branch\n",
    "-------------------------------------\n",
    "\n",
    "Creating two tables under the `dev` branch:\n",
    "- region\n",
    "- nation\n",
    "\n",
    "It is not yet possible to create table using pyspark and iceberg, so Java code is used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"nessie.ref\", \"dev\")\n",
    "catalog = jvm.NessieCatalog(sc._jsc.hadoopConfiguration())\n",
    "\n",
    "# Creating region table\n",
    "region_name = jvm.TableIdentifier.parse(\"testing.region\")\n",
    "region_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"R_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"R_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"R_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "region_spec = jvm.PartitionSpec.unpartitioned()\n",
    "\n",
    "region_table = catalog.createTable(region_name, region_schema, region_spec)\n",
    "region_df = spark.read.load(\"data/region.parquet\")\n",
    "region_df.write.option('hadoop.nessie.ref', 'dev').format(\"iceberg\").mode(\"overwrite\").save(\"testing.region\")\n",
    "\n",
    "# Creating nation table\n",
    "nation_name = jvm.TableIdentifier.parse(\"testing.nation\")\n",
    "nation_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"N_NATIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"N_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"N_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(4, \"N_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "nation_spec = jvm.PartitionSpec.builderFor(nation_schema).truncate(\"N_NAME\", 2).build()\n",
    "nation_table = catalog.createTable(nation_name, nation_schema, nation_spec)\n",
    "\n",
    "nation_df = spark.read.load(\"data/nation.parquet\")\n",
    "nation_df.write.option('hadoop.nessie.ref', 'dev').format(\"iceberg\").mode(\"overwrite\").save(\"testing.nation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated tables\n",
    "----------------------------\n",
    "   \n",
    "Check tables generated under the dev branch (and that the main branch does not have any tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries(entries=[], has_more=False, token=None)\n"
     ]
    }
   ],
   "source": [
    "!nessie list-tables main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries(entries=[Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'nation'])), Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'region']))], has_more=False, token=None)\n"
     ]
    }
   ],
   "source": [
    "!nessie list-tables dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `dev` and `main` branches point to different commits now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"e0b41c30f0710277532f51242994e10acfdc46bf\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"main\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"133fc5ce95c57a7a92f03305c855579e1a0585d0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dev\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nessie list-references | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev promotion\n",
    "-------------\n",
    "\n",
    "Promote dev branch promotion to main.\n",
    "\n",
    "* main now has the same tables as dev\n",
    "* main and dev point to the same commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!nessie assign-branch main dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries(entries=[Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'nation'])), Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'region']))], has_more=False, token=None)\n"
     ]
    }
   ],
   "source": [
    "!nessie list-tables main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"133fc5ce95c57a7a92f03305c855579e1a0585d0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"main\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[1;39m{\n",
      "    \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"BRANCH\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"hash\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"133fc5ce95c57a7a92f03305c855579e1a0585d0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dev\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!nessie list-references | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `etl` branch\n",
    "----------------------\n",
    "\n",
    "- Create a branch `etl` out of `main`\n",
    "- add data to nation\n",
    "- alter the schema of region\n",
    "- create table city\n",
    "- query the tables in `etl`\n",
    "- query the tables in `main`\n",
    "- promote `etl` branch to `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!nessie create-branch etl -r `nessie show-reference main | jq .hash | sed 's/\"//g'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nation = Row(\"N_NATIONKEY\", \"N_NAME\", \"N_REGIONKEY\", \"N_COMMENT\")\n",
    "new_nations = spark.createDataFrame([\n",
    "    Nation(25, \"SYLDAVIA\", 3, \"King Ottokar's Sceptre\"),\n",
    "    Nation(26, \"SAN THEODOROS\", 1, \"The Picaros\")])\n",
    "new_nations.write.option('hadoop.nessie.ref', 'etl').format(\"iceberg\").mode(\"append\").save(\"testing.nation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the default branch\n",
    "hadoop_conf.set('nessie.ref', 'etl')\n",
    "\n",
    "etl_catalog = jvm.NessieCatalog(hadoop_conf)\n",
    "etl_catalog.loadTable(region_name).updateSchema().addColumn('R_ABBREV', jvm.Types.StringType.get()).commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating city table\n",
    "sc.getConf().set(\"spark.hadoop.nessie.ref\", \"etl\")\n",
    "spark.sql(\"CREATE TABLE nessie.testing.city (C_CITYKEY BIGINT, C_NAME STRING, N_NATIONKEY BIGINT, C_COMMNT STRING) USING iceberg PARTITIONED BY (N_NATIONKEY)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntryName(elements=['testing', 'nation']),\n",
       " EntryName(elements=['testing', 'region'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynessie import init\n",
    "nessie = init()\n",
    "[i.name for i in nessie.list_tables('main').entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntryName(elements=['testing', 'city']),\n",
       " EntryName(elements=['testing', 'nation']),\n",
       " EntryName(elements=['testing', 'region'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.name for i in nessie.list_tables('etl').entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': '133fc5ce95c57a7a92f03305c855579e1a0585d0',\n",
       " 'dev': '133fc5ce95c57a7a92f03305c855579e1a0585d0',\n",
       " 'etl': '4defe1e37e300cb890c4dd8509089ed9e5103ec5'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i.name:i.hash_ for i in nessie.list_references()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nessie.assign('main','etl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main': '4defe1e37e300cb890c4dd8509089ed9e5103ec5',\n",
       " 'dev': '133fc5ce95c57a7a92f03305c855579e1a0585d0',\n",
       " 'etl': '4defe1e37e300cb890c4dd8509089ed9e5103ec5'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i.name:i.hash_ for i in nessie.list_references()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `experiment` branch\n",
    "--------------------------------\n",
    "\n",
    "- create `experiment` branch from `main`\n",
    "- drop `nation` table\n",
    "- add data to `region` table\n",
    "- compare `experiment` and `main` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!nessie create-branch experiment -r `nessie show-reference main | jq .hash | sed 's/\"//g'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the default branch\n",
    "hadoop_conf.set('nessie.ref', 'experiment')\n",
    "\n",
    "catalog = jvm.NessieCatalog(hadoop_conf)\n",
    "catalog.dropTable(jvm.TableIdentifier.parse(\"testing.nation\"), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"set spark.hadoop.nessie.ref=experiment\")\n",
    "spark.sql('INSERT INTO TABLE nessie.testing.region VALUES (5, \"AUSTRALIA\", \"Let\\'s hop there\", \"AUS\")')\n",
    "spark.sql('INSERT INTO TABLE nessie.testing.region VALUES (6, \"ANTARTICA\", \"It\\'s cold\", \"ANT\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries(entries=[Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'city'])), Entry(kind='UNKNOWN', name=EntryName(elements=['testing', 'region']))], has_more=False, token=None)\n"
     ]
    }
   ],
   "source": [
    "!nessie list-tables experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the contents of the region table on the experiment branch. Notice the use of the `nessie` catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_REGIONKEY</th>\n",
       "      <th>R_NAME</th>\n",
       "      <th>R_COMMENT</th>\n",
       "      <th>R_ABBREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>lar deposits. blithely final packages cajole. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>hs use ironic, even requests. s</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>ges. thinly even pinto beans ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EUROPE</td>\n",
       "      <td>ly final courts cajole furiously final excuse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MIDDLE EAST</td>\n",
       "      <td>uickly special accounts cajole carefully blith...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Let's hop there</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ANTARTICA</td>\n",
       "      <td>It's cold</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_REGIONKEY       R_NAME  \\\n",
       "0            0       AFRICA   \n",
       "1            1      AMERICA   \n",
       "2            2         ASIA   \n",
       "3            3       EUROPE   \n",
       "4            4  MIDDLE EAST   \n",
       "5            5    AUSTRALIA   \n",
       "6            6    ANTARTICA   \n",
       "\n",
       "                                           R_COMMENT R_ABBREV  \n",
       "0  lar deposits. blithely final packages cajole. ...     None  \n",
       "1                    hs use ironic, even requests. s     None  \n",
       "2                    ges. thinly even pinto beans ca     None  \n",
       "3      ly final courts cajole furiously final excuse     None  \n",
       "4  uickly special accounts cajole carefully blith...     None  \n",
       "5                                    Let's hop there      AUS  \n",
       "6                                          It's cold      ANT  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from nessie.testing.region\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare to the contents of the region table on the main branch. Notice the use of `@main` to view data on the main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_REGIONKEY</th>\n",
       "      <th>R_NAME</th>\n",
       "      <th>R_COMMENT</th>\n",
       "      <th>R_ABBREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>lar deposits. blithely final packages cajole. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>hs use ironic, even requests. s</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>ges. thinly even pinto beans ca</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EUROPE</td>\n",
       "      <td>ly final courts cajole furiously final excuse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MIDDLE EAST</td>\n",
       "      <td>uickly special accounts cajole carefully blith...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_REGIONKEY       R_NAME  \\\n",
       "0            0       AFRICA   \n",
       "1            1      AMERICA   \n",
       "2            2         ASIA   \n",
       "3            3       EUROPE   \n",
       "4            4  MIDDLE EAST   \n",
       "\n",
       "                                           R_COMMENT R_ABBREV  \n",
       "0  lar deposits. blithely final packages cajole. ...     None  \n",
       "1                    hs use ironic, even requests. s     None  \n",
       "2                    ges. thinly even pinto beans ca     None  \n",
       "3      ly final courts cajole furiously final excuse     None  \n",
       "4  uickly special accounts cajole carefully blith...     None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from nessie.testing.`region@main`\").toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
